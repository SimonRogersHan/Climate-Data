{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdVXxLyXZlKUFbi8+NPOUZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"10Fo3Tnbj-Rl"},"outputs":[],"source":["\n","#Install the library"]},{"cell_type":"code","source":["!pip install eemont rasterio geopy"],"metadata":{"id":"AqflOs-fkFpG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import Libraries\n","\n","import ee  # Google Earth Engine\n","import eemont  # Extension to Google Earth Engine\n","\n","from PIL import Image\n","import requests\n","import rasterio\n","import numpy as np\n","import datetime\n","import geopy\n","import geopy.distance\n","import matplotlib.pyplot as plt"],"metadata":{"id":"EzSP4CNRkHUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install geemap"],"metadata":{"id":"kQynR9VrkKH3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ee.Authenticate()\n","ee.Initialize()"],"metadata":{"id":"ySm6FH3zkNK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Boundary points were taken from this dataset \"geoBoundaries/600/ADM2\", selection criteria has been discussed in the main paper"],"metadata":{"id":"AFXMroCSkgpn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We choose only certain boundaries  (which have been explained in the paper in detail) from this above dataset for each region of our study, then download the TIF images from 2013 to 2019 (Daily frequecny)"],"metadata":{"id":"yWEDZqbPng93"}},{"cell_type":"code","source":["#Delhi -"],"metadata":{"id":"qBq4HW_fnc_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install earthengine-api geemap\n","\n","import ee\n","import geemap\n","from datetime import datetime, timedelta\n","import os\n","import requests\n","\n","# Authenticate and initialize the Earth Engine library\n","ee.Authenticate()\n","ee.Initialize(project='klklk-klkl')\n","\n","\n","# Load the administrative boundaries FeatureCollection\n","admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region_names = ['New Delhi', 'Gurgaon', 'West', 'South West', 'South', 'South East',\n","          'Gautam Buddha Nagar', 'North East', 'North', 'Central', 'North West',\n","          'North East', 'Shahdara', 'Ghaziabad', 'East']\n","\n","country_code = 'IND'  # Use 'IND' instead of 'India'\n","\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Filter the FeatureCollection to include only the specified regions\n","\n","\n","# Get the geometry of the filtered features\n","geometry = admin1_filtered.geometry()\n","\n","# Load the VIIRS ImageCollection for the specified date range\n","start_date = datetime(2013, 1, 25)\n","end_date = datetime(2019,11, 5)\n","\n","\n","# Create a directory to save the images\n","output_folder = \"NTL_Delhi_BoundTF\"\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","# Loop through each date in the date range\n","current_date = start_date\n","while current_date <= end_date:\n","    try:\n","        # Format the date\n","        date_str = current_date.strftime('%Y-%m-%d')\n","\n","        # Filter the VIIRS ImageCollection for the specific date\n","        dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP46A2').filter(\n","            ee.Filter.date(date_str)\n","        )\n","\n","        # Select the BRDF band and clip the images to the geometry\n","        brdf = dataset.select('Gap_Filled_DNB_BRDF_Corrected_NTL')\n","        clipped_brdf = brdf.map(lambda image: image.clip(geometry))\n","\n","        # Get the median image for the day\n","        median_image = clipped_brdf.median()\n","\n","        # Generate the download URL for the GeoTIFF\n","        download_url = median_image.getDownloadURL({\n","            'region': geometry,\n","            'bands': ['Gap_Filled_DNB_BRDF_Corrected_NTL'],\n","            'min': 0,\n","            'max': 100,\n","            'format': 'GeoTIFF',\n","            'dimensions': [1024, 1024],  # Adjust the resolution as needed\n","        })\n","\n","        # Fetch and save the GeoTIFF\n","        output_filename = f\"viirs_Cairo_{date_str}.tif\"\n","        output_filepath = os.path.join(output_folder, output_filename)\n","        geotiff_response = requests.get(download_url, stream=True)\n","\n","        with open(output_filepath, \"wb\") as f:\n","            for chunk in geotiff_response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","\n","        print(f\"Downloaded: {output_filename}\")\n","\n","    except ee.ee_exception.EEException as e:\n","        print(f\"Error for date {date_str}: {str(e)}\")\n","        print(f\"Skipping date {date_str} due to missing data or band.\")\n","\n","    # Move to the next day\n","    current_date += timedelta(days=1)\n","\n","print(\"All images have been downloaded.\")\n"],"metadata":{"id":"LYLVAJkMkThe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Cairo"],"metadata":{"id":"xRLaCXIq20hS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install earthengine-api geemap\n","\n","import ee\n","import geemap\n","from datetime import datetime, timedelta\n","import os\n","import requests\n","\n","# Authenticate and initialize the Earth Engine library\n","ee.Authenticate()\n","ee.Initialize(project='klklk-klkl')\n","\n","\n","# Load the administrative boundaries FeatureCollection\n","admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region = ['Sayyida Zainab', 'Qasr Al-Nile', 'Al Azbakiyya' , 'Rud Al-Farag', 'Shubra', 'Misr Al-Qadima',  'Abdin', 'Muski' , 'Zawiyya Al-Hamra',  'Al Sharabiyya', 'Al Sahil', 'Zamalik' ,\n","          'Bulaq', 'Hadaiq Al-Qubba', 'Al Wayli', 'Al Zahir', 'Al Darb al-Ahmar', 'Bab Al-Shariyya']\n","\n","country_code = 'EGY'  # Use 'IND' instead of 'India'\n","\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Filter the FeatureCollection to include only the specified regions\n","\n","\n","# Get the geometry of the filtered features\n","geometry = admin1_filtered.geometry()\n","\n","# Load the VIIRS ImageCollection for the specified date range\n","start_date = datetime(2013, 1, 25)\n","end_date = datetime(2019,11, 5)\n","\n","\n","# Create a directory to save the images\n","output_folder = \"NTL_Delhi_BoundTF\"\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","# Loop through each date in the date range\n","current_date = start_date\n","while current_date <= end_date:\n","    try:\n","        # Format the date\n","        date_str = current_date.strftime('%Y-%m-%d')\n","\n","        # Filter the VIIRS ImageCollection for the specific date\n","        dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP46A2').filter(\n","            ee.Filter.date(date_str)\n","        )\n","\n","        # Select the BRDF band and clip the images to the geometry\n","        brdf = dataset.select('Gap_Filled_DNB_BRDF_Corrected_NTL')\n","        clipped_brdf = brdf.map(lambda image: image.clip(geometry))\n","\n","        # Get the median image for the day\n","        median_image = clipped_brdf.median()\n","\n","        # Generate the download URL for the GeoTIFF\n","        download_url = median_image.getDownloadURL({\n","            'region': geometry,\n","            'bands': ['Gap_Filled_DNB_BRDF_Corrected_NTL'],\n","            'min': 0,\n","            'max': 100,\n","            'format': 'GeoTIFF',\n","            'dimensions': [1024, 1024],  # Adjust the resolution as needed\n","        })\n","\n","        # Fetch and save the GeoTIFF\n","        output_filename = f\"viirs_Cairo_{date_str}.tif\"\n","        output_filepath = os.path.join(output_folder, output_filename)\n","        geotiff_response = requests.get(download_url, stream=True)\n","\n","        with open(output_filepath, \"wb\") as f:\n","            for chunk in geotiff_response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","\n","        print(f\"Downloaded: {output_filename}\")\n","\n","    except ee.ee_exception.EEException as e:\n","        print(f\"Error for date {date_str}: {str(e)}\")\n","        print(f\"Skipping date {date_str} due to missing data or band.\")\n","\n","    # Move to the next day\n","    current_date += timedelta(days=1)\n","\n","print(\"All images have been downloaded.\")\n"],"metadata":{"id":"Vz8c79gP22qC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Sao Palo"],"metadata":{"id":"4bXYsxf25IR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install earthengine-api geemap\n","\n","import ee\n","import geemap\n","from datetime import datetime, timedelta\n","import os\n","import requests\n","\n","# Authenticate and initialize the Earth Engine library\n","ee.Authenticate()\n","ee.Initialize(project='klklk-klkl')\n","\n","\n","# Load the administrative boundaries FeatureCollection\n","admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region = ['SÃ£o Paulo']\n","\n","country_code = 'BRA'  # Use 'IND' instead of 'India'\n","\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Filter the FeatureCollection to include only the specified regions\n","\n","\n","# Get the geometry of the filtered features\n","geometry = admin1_filtered.geometry()\n","\n","# Load the VIIRS ImageCollection for the specified date range\n","start_date = datetime(2013, 1, 25)\n","end_date = datetime(2019,11, 5)\n","\n","\n","# Create a directory to save the images\n","output_folder = \"NTL_Delhi_BoundTF\"\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","# Loop through each date in the date range\n","current_date = start_date\n","while current_date <= end_date:\n","    try:\n","        # Format the date\n","        date_str = current_date.strftime('%Y-%m-%d')\n","\n","        # Filter the VIIRS ImageCollection for the specific date\n","        dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP46A2').filter(\n","            ee.Filter.date(date_str)\n","        )\n","\n","        # Select the BRDF band and clip the images to the geometry\n","        brdf = dataset.select('Gap_Filled_DNB_BRDF_Corrected_NTL')\n","        clipped_brdf = brdf.map(lambda image: image.clip(geometry))\n","\n","        # Get the median image for the day\n","        median_image = clipped_brdf.median()\n","\n","        # Generate the download URL for the GeoTIFF\n","        download_url = median_image.getDownloadURL({\n","            'region': geometry,\n","            'bands': ['Gap_Filled_DNB_BRDF_Corrected_NTL'],\n","            'min': 0,\n","            'max': 100,\n","            'format': 'GeoTIFF',\n","            'dimensions': [1024, 1024],  # Adjust the resolution as needed\n","        })\n","\n","        # Fetch and save the GeoTIFF\n","        output_filename = f\"viirs_Cairo_{date_str}.tif\"\n","        output_filepath = os.path.join(output_folder, output_filename)\n","        geotiff_response = requests.get(download_url, stream=True)\n","\n","        with open(output_filepath, \"wb\") as f:\n","            for chunk in geotiff_response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","\n","        print(f\"Downloaded: {output_filename}\")\n","\n","    except ee.ee_exception.EEException as e:\n","        print(f\"Error for date {date_str}: {str(e)}\")\n","        print(f\"Skipping date {date_str} due to missing data or band.\")\n","\n","    # Move to the next day\n","    current_date += timedelta(days=1)\n","\n","print(\"All images have been downloaded.\")\n"],"metadata":{"id":"6Qwa-L8Y5KXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Guangzhou"],"metadata":{"id":"Wr-QX5Uy5lTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install earthengine-api geemap\n","\n","import ee\n","import geemap\n","from datetime import datetime, timedelta\n","import os\n","import requests\n","\n","# Authenticate and initialize the Earth Engine library\n","ee.Authenticate()\n","ee.Initialize(project='klklk-klkl')\n","\n","\n","# Load the administrative boundaries FeatureCollection\n","admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region = ['Panyushi', 'Guangzhoushi', 'Zengchengshi', 'Huadushi', 'Chonghuashi']\n","\n","country_code = 'CHN'  # Use 'IND' instead of 'India'\n","\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Filter the FeatureCollection to include only the specified regions\n","\n","\n","# Get the geometry of the filtered features\n","geometry = admin1_filtered.geometry()\n","\n","# Load the VIIRS ImageCollection for the specified date range\n","start_date = datetime(2013, 1, 25)\n","end_date = datetime(2019,11, 5)\n","\n","\n","# Create a directory to save the images\n","output_folder = \"NTL_Delhi_BoundTF\"\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","# Loop through each date in the date range\n","current_date = start_date\n","while current_date <= end_date:\n","    try:\n","        # Format the date\n","        date_str = current_date.strftime('%Y-%m-%d')\n","\n","        # Filter the VIIRS ImageCollection for the specific date\n","        dataset = ee.ImageCollection('NOAA/VIIRS/001/VNP46A2').filter(\n","            ee.Filter.date(date_str)\n","        )\n","\n","        # Select the BRDF band and clip the images to the geometry\n","        brdf = dataset.select('Gap_Filled_DNB_BRDF_Corrected_NTL')\n","        clipped_brdf = brdf.map(lambda image: image.clip(geometry))\n","\n","        # Get the median image for the day\n","        median_image = clipped_brdf.median()\n","\n","        # Generate the download URL for the GeoTIFF\n","        download_url = median_image.getDownloadURL({\n","            'region': geometry,\n","            'bands': ['Gap_Filled_DNB_BRDF_Corrected_NTL'],\n","            'min': 0,\n","            'max': 100,\n","            'format': 'GeoTIFF',\n","            'dimensions': [1024, 1024],  # Adjust the resolution as needed\n","        })\n","\n","        # Fetch and save the GeoTIFF\n","        output_filename = f\"viirs_Cairo_{date_str}.tif\"\n","        output_filepath = os.path.join(output_folder, output_filename)\n","        geotiff_response = requests.get(download_url, stream=True)\n","\n","        with open(output_filepath, \"wb\") as f:\n","            for chunk in geotiff_response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","\n","        print(f\"Downloaded: {output_filename}\")\n","\n","    except ee.ee_exception.EEException as e:\n","        print(f\"Error for date {date_str}: {str(e)}\")\n","        print(f\"Skipping date {date_str} due to missing data or band.\")\n","\n","    # Move to the next day\n","    current_date += timedelta(days=1)\n","\n","print(\"All images have been downloaded.\")\n"],"metadata":{"id":"C92d3xaO5jYt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Now I create json file for each city separateltly, which contains data of thier used when extracting NTL values from them"],"metadata":{"id":"F2emJNHA5427"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Delhi"],"metadata":{"id":"75XC14JN7rwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region_names = ['New Delhi', 'Gurgaon', 'West', 'South West', 'South', 'South East',\n","          'Gautam Buddha Nagar', 'North East', 'North', 'Central', 'North West',\n","          'North East', 'Shahdara', 'Ghaziabad', 'East']\n","\n","country_code = 'IND'  # Use 'IND' instead of 'India'\n","\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Export the geometry as a GeoJSON file\n","geojson = admin1_filtered.getInfo()\n","with open(\"Delhi_geometry.geojson3\", \"w\") as f:\n","    import json\n","    json.dump(geojson, f)"],"metadata":{"id":"NSPCI5Za7oB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Cairo"],"metadata":{"id":"mZsJItkS7xPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region = ['Sayyida Zainab', 'Qasr Al-Nile', 'Al Azbakiyya' , 'Rud Al-Farag', 'Shubra', 'Misr Al-Qadima',  'Abdin', 'Muski' , 'Zawiyya Al-Hamra',  'Al Sharabiyya', 'Al Sahil', 'Zamalik' ,\n","          'Bulaq', 'Hadaiq Al-Qubba', 'Al Wayli', 'Al Zahir', 'Al Darb al-Ahmar', 'Bab Al-Shariyya']\n","\n","country_code = 'EGY'\n","\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Export the geometry as a GeoJSON file\n","geojson = admin1_filtered.getInfo()\n","with open(\"Delhi_geometry.geojson3\", \"w\") as f:\n","    import json\n","    json.dump(geojson, f)"],"metadata":{"id":"jnEsdhxN70fD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Sao Palo"],"metadata":{"id":"t7vlhHNO77z-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region = ['SÃ£o Paulo']\n","\n","country_code = 'BRA'\n","\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Export the geometry as a GeoJSON file\n","geojson = admin1_filtered.getInfo()\n","with open(\"Delhi_geometry.geojson3\", \"w\") as f:\n","    import json\n","    json.dump(geojson, f)"],"metadata":{"id":"FaVhLRC58Ape"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Guangzhou"],"metadata":{"id":"eD6hkij88R93"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["admin1 = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM2\")\n","\n","# Define the regions of interest\n","region = ['Panyushi', 'Guangzhoushi', 'Zengchengshi', 'Huadushi', 'Chonghuashi']\n","\n","country_code = 'CHN'\n","# Filter the FeatureCollection\n","admin1_filtered = admin1.filter(\n","    ee.Filter.And(\n","        ee.Filter.inList('shapeName', region_names),\n","        ee.Filter.eq('shapeGroup', country_code)  # Ensure correct country\n","    )\n",")\n","\n","\n","# Export the geometry as a GeoJSON file\n","geojson = admin1_filtered.getInfo()\n","with open(\"Delhi_geometry.geojson3\", \"w\") as f:\n","    import json\n","    json.dump(geojson, f)"],"metadata":{"id":"e5IVqDXG8Vxj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we extract the NTL data from these TIF images (Explained in detail in the main paper and create a time series data for NTL which is then used in our analysis"],"metadata":{"id":"cC-xDt3m8qcK"}},{"cell_type":"code","source":["import rasterio\n","import rasterio.mask\n","import geopandas as gpd\n","import numpy as np\n","import pandas as pd\n","import os\n","from glob import glob\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","\n","# Paths to input files\n","geojson_file = \"/path\"  # GeoJSON file with your geometry\n","directory = \"/path\"  # Directory containing your GeoTIFF files\n","file_pattern = \"*.tif\"  # File pattern to match\n","\n","# Load the GeoJSON file using GeoPandas\n","gdf = gpd.read_file(geojson_file)\n","\n","# List all GeoTIFF files in the directory\n","tif_files = sorted(glob(os.path.join(directory, file_pattern)))\n","\n","# Function to extract dates from file names\n","def extract_date_from_filename(filename):\n","    # Example filename format: 'viirs_shenzhen_2018-02-10.tif'\n","    date_str = os.path.basename(filename).split('_')[-1].replace('.tif', '')\n","    return datetime.strptime(date_str, '%Y-%m-%d')\n","\n","# Create a dictionary mapping dates to file names\n","file_date_mapping = {extract_date_from_filename(fname): fname for fname in tif_files}\n","\n","# Define the date range\n","start_date = datetime(2013, 2, 15)\n","end_date = datetime(2019, 10, 21)\n","dates = pd.date_range(start=start_date, end=end_date)\n","\n","# Initialize lists to store results\n","mean_radiances = []\n","invalid_files = []\n","\n","# Loop through the desired date range\n","for current_date in dates:\n","    if current_date in file_date_mapping:\n","        fname = file_date_mapping[current_date]\n","        try:\n","            with rasterio.open(fname) as src:\n","                # Ensure the CRS of the GeoJSON matches the GeoTIFF\n","                if gdf.crs != src.crs:\n","                    gdf = gdf.to_crs(src.crs)\n","\n","                # Clip the raster to the geometry\n","                out_image, out_transform = rasterio.mask.mask(src, gdf.geometry, crop=True, nodata=np.nan)\n","                raster_data = out_image[0]  # Assuming single-band raster\n","\n","                # Mask out invalid or gap-filled pixels\n","                fill_value = 65535\n","                masked_raster_data = np.where(raster_data != fill_value, raster_data, np.nan)\n","\n","                # Get pixel resolution and calculate area\n","                pixel_width, pixel_height = out_transform[0], -out_transform[4]\n","                pixel_area = pixel_width * pixel_height  # in square meters\n","\n","                # Calculate total weighted radiance and total area\n","                total_weighted_radiance = np.nansum(masked_raster_data * pixel_area)\n","                total_area = np.sum(~np.isnan(masked_raster_data)) * pixel_area\n","\n","                # Calculate mean area-weighted radiance\n","                if total_area > 0:\n","                    mean_radiance = total_weighted_radiance / total_area\n","                else:\n","                    mean_radiance = np.nan\n","\n","                mean_radiances.append(mean_radiance)\n","        except rasterio.errors.RasterioIOError:\n","            # If the file cannot be opened, log the file name\n","            print(f\"Skipping unsupported file: {fname}\")\n","            invalid_files.append(fname)\n","            mean_radiances.append(np.nan)\n","    else:\n","        # If no file is found for the date, append NaN\n","        print(f\"No file found for date: {current_date}\")\n","        mean_radiances.append(np.nan)\n","\n","# Create a DataFrame to store results\n","output_df = pd.DataFrame({\n","    \"Date\": dates,\n","    \"Mean Area-Weighted Radiance\": mean_radiances,\n","})\n","\n","# Save results to an Excel sheet\n","output_excel_path = \"/path\"\n","output_df.to_excel(output_excel_path, index=False)\n","\n","# Print a summary\n","print(\"Results saved to:\", output_excel_path)\n","print(\"Skipped files:\", invalid_files)\n","\n","# Plot the time series\n","plt.figure(figsize=(14, 8))\n","plt.plot(output_df[\"Date\"], output_df[\"Mean Area-Weighted Radiance\"], marker=\"o\", markersize=2, label=\"Mean Area-Weighted Radiance\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Radiance (unit)\")\n","plt.title(\"Mean Area-Weighted Radiance (2013-2019)\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"wYq4XSru8ouu"},"execution_count":null,"outputs":[]}]}